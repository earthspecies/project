# October 10, 2020 - Earth Species Project Machine Learning & Bioacoustics Workshop hosted by Interspecies.IO

It was a tremendous honor to present to the Interspecies.io community and share our latest work. We are privileged to be part of this incredible collective working together to deepen the understanding of animal communication and language.

- October 10, 2020, 11 AM EDT
- Attendees: ~100 biologists, computational linguists, information theorists, musicians, and technologists 

## Watch

[![video thumb](https://i.imgur.com/XwZq1TS.png)](https://archive.org/details/20201010-interspecies-i-o-earth-species-project-ai-toolbox)

## Discuss
There was a Q&A discussion following the presentation. Continue the conversation and ask more questions [here](https://github.com/earthspecies/project/discussions/35).

## Resources

**JUPYTER NOTEBOOKS**

- [Cocktail Party Problem](https://github.com/earthspecies/cocktail-party-problem) 
- [Acoustic representation toolbox](https://github.com/earthspecies/acoustic-representation-toolbox)
- [Denoising, detection, and classification](https://github.com/earthspecies/dolphin-strandings)
- [Earth Species Library](https://github.com/earthspecies/library)

If you are interested in contributing your bioacoustic data to the Earth Species Library, please get in touch with us at katie@earthspecies.org.

**GETTING STARTED MATERIAL**
- Intro to using [Collab](https://colab.research.google.com/notebooks/intro.ipynb)
- 

**[ACADEMIC REFERENCES](https://github.com/earthspecies/cocktail-party-problem/blob/main/Bookshelf/Library.md)**
1. [The “Cocktail Party Problem”: What Is It? How Can It Be Solved? And Why Should Animal Behaviorists Study It?](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2692487/)
2. [Asteroid: The PyTorch-Based Audio Source Separation Toolkit for Researchers](https://arxiv.org/abs/2005.04132)
3. [Wavesplit: End-to-End Speech Separation by Speaker Clustering](https://arxiv.org/abs/2002.08933)
4. [Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation](https://arxiv.org/abs/2007.13975)
5. [Voice Separation with an Unknown Number of Multiple Speakers](https://arxiv.org/abs/2003.01531)
6. [Separation of Overlapping Sources in Bioacoustic Mixtures](https://asa.scitation.org/doi/10.1121/10.0000932)
7. [Separating Overlapping Bat Calls with a Bi-Directional Long Short-Term Memory Network](https://www.biorxiv.org/content/10.1101/2019.12.15.876656v1)
8. [Music Source Separation in the Waveform Domain](https://arxiv.org/abs/1911.13254)
9. [Deep Audio Prior](https://arxiv.org/abs/1912.10292)
10. [Deep Learning for Monaural Speech Separation](https://paris.cs.illinois.edu/pubs/huang-icassp2014.pdf)
11. [The Separation of Overlapped Dolphin Signature Whistle Based on Blind Source Separation](https://ieeexplore.ieee.org/document/8242534)
12. [A Comparative Study of Blind Source Separation for Bioacoustics Sounds based on FastICA, PCA and NMF](https://www.sciencedirect.com/science/article/pii/S1877050918312468?via%3Dihub)
13. [Investigating Deep Neural Transformations for Spectrogram-Based Musical Source Separation](https://arxiv.org/abs/1912.02591)
14. [A Physiologically Inspired Model for Solving the Cocktail Party Problem](https://link.springer.com/content/pdf/10.1007/s10162-019-00732-4.pdf)
15. [Audio Source Separation with Discriminative Scattering Networks](https://arxiv.org/abs/1412.7022)
16. [Blind Nonnegative Source Separation Using Biological Neural Networks](https://arxiv.org/abs/1706.00382)

**MISCELLANEOUS RESOURCES**
1. [End-to-End Overlapped Speech Detection and Speaker Counting with Raw Waveform](https://ieeexplore.ieee.org/document/9003962)
2. [Perceptual and Neural Mechanisms of Auditory Scene Analysis in the European Starling](https://link.springer.com/chapter/10.1007/978-3-319-48690-1_3)
3. [Neuromorphic Model for Sound Source Segregation](https://drum.lib.umd.edu/handle/1903/18155)
4. [Efficient Trainable Front-Ends for Neural Speech Enhancement](https://arxiv.org/abs/2002.09286)
5. [Finding Strength in Weakness: Learning to Separate Sounds with Weak Supervision](https://arxiv.org/abs/1911.02182)
6. [Monaural Source Separation Based on Sequentially Trained LSTMs in Real Room Environments](https://ieeexplore.ieee.org/document/8902640)
7. [The Phasebook: Building Complex Masks via Discrete Representations for Source Separation](https://waseda.pure.elsevier.com/en/publications/the-phasebook-building-complex-masks-via-discrete-representations)
8. [Universal Sound Separation](https://arxiv.org/abs/1905.03330)
9. [Speaker-independent Speech Separation with Deep Attractor Network](https://arxiv.org/abs/1707.03634)
10. [Deep Clustering and Conventional Networks for Music Separation: Stronger Together](https://arxiv.org/abs/1611.06265)
11. [Phase-Sensitive and Recognition-Boosted Speech Separation Using Deep Recurrent Neural Networks](https://ieeexplore.ieee.org/document/7178061)
12. [Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation](https://arxiv.org/abs/1502.04149)
13. [Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation](https://arxiv.org/abs/1809.07454)
14. [Deep Learning Based Phase Reconstruction for Speaker Separation: A Trigonometric Perspective](https://arxiv.org/abs/1811.09010)
15. [Divide and Conquer: A Deep CASA Approach to Talker-independent Monaural Speaker Separation](https://arxiv.org/abs/1904.11148)
16. [Dual-Path RNN: Efficient Long Sequence Modeling for Time-Domain Single-Channel Speech Separation](https://arxiv.org/abs/1910.06379)
17. [A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation](https://arxiv.org/abs/1905.07497)
18. [FurcaNeXt: End-to-End Monaural Speech Separation with Dynamic Gated Dilated Temporal Convolutional Networks](https://arxiv.org/abs/1902.04891)
19. [Improving Universal Sound Separation Using Sound Classification](https://arxiv.org/abs/1911.07951)
20. [SpEx: Multi-Scale Time Domain Speaker Extraction Network](https://arxiv.org/abs/2004.08326)
21. [Meta-Learning Extractors for Music Source Separation](https://arxiv.org/abs/2002.07016)
22. [Unsupervised Learning of Semantic Audio Representations](https://arxiv.org/abs/1711.02209)
23. [Sudo rm -rf: Efficient Networks for Universal Audio Source Separation](https://arxiv.org/abs/2007.06833)
24. [Unsupervised Sound Separation Using Mixtures of Mixtures](https://arxiv.org/abs/2006.12701)
25. [Listen to What You Want: Neural Network-based Universal Sound Selector](https://arxiv.org/abs/2006.05712)
26. [Speech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss](https://arxiv.org/abs/2008.03149)
27. [Identify Speakers in Cocktail Parties with End-to-End Attention](https://arxiv.org/abs/2005.11408)
    
**MACHINE LEARNING CONCEPTS**
1. Matched Filters
2. Hilbert Huang Transforms
3. Lombard Effect
4. Dip-Listening Hypothesis
5. Noise-Invariant, Rule-Encoding, and Temporal Edge Neurons
6. FastICA (Independent Component Analysis), Point Source Separation (PSS), Non-Negative Matrix Factorization (NMF)
7. Cortical Representation of Speech, Auditory Object Analysis
8. Deep Scattering Spectrum, Kymatio, Invariant Scattering Convolution Networks
9. Error-Gated Hebbian Rule
10. Probabilistic Latent Component Analysis (PLCA), Robust PCA (RPCA), Low-Rank Modeling
11. Progressive Learning
12. Denoising Autoencoders
13. Temporal Convolutional Networks (TCNs)
14. Perfect Reconstruction Filterbank (PRFB), Gammatone Filterbank
15. Deep Feature Losses, Short-Time Objective Intelligibility (STOI), Perceptual Evaluation of Speech Quality (PESQ)
16. Wiener Filtering
17. Permutation Invariant Training
18. Supervised Independent Vector Analysis
19. Phase Spectra and Group Delay
20. Spectrogram Fusion
21. Self-Organizing Background Subtraction
22. Phase-Aware Signal Processing
23. Deep Clustering, Deep Attractor, and Selective Hearing Networks
24. Multimodal/Crossmodal Fusion   

