# October 10, 2020 - Earth Species Project Machine Learning & Bioacoustics Workshop

## hosted by Interspecies.IO

It was a tremendous honor to present to the [Interspecies.io](https://interspecies.io/) community and share our latest work. The workshop was hosted by Interspecies.IO, a multidisciplinary group founded by Peter Gabriel (musician and activist), Dr. Vint Cerf (Vice President at Google and Co-designer of the Internet), Dr. Diana Reiss (Professor at Hunter College, a cognitive psychologist, and marine mammal scientist), and Dr. Neil Gershenfeld (head of MIT’s Center for Bits and Atoms).

## Attendees: 

Nearly 100 biologists, computational linguists, computer scientists and engineers, information theorists, musicians, and artists. Continue the conversation with us [here](https://github.com/earthspecies/project/discussions/35). 


## Recording: 
[![video thumb](https://i.imgur.com/XwZq1TS.png)](https://archive.org/details/20201010-interspecies-i-o-earth-species-project-ai-toolbox)


## Opensource Code: 
 
 * [Cocktail Party Problem](https://github.com/earthspecies/cocktail-party-problem)
 * [Acoustic representation toolbox ](https://github.com/earthspecies/acoustic-representation-toolbox)
 * [Denoising, detection, and classification](https://github.com/earthspecies/dolphin-strandings)
 * [ESP Library](https://github.com/earthspecies/library)


## Participate: 

The Earth Species Library is a collection of universally accessible bioacoustics datasets, ranging from humpback whales to zebra finches, tuned for machine learning. These datasets will enable machine learning researchers to train and validate novel machine learning methodologies and develop increasingly complex approaches to answer some of biology's most elusive questions. If you are interested in contributing your bioacoustic data and annotations to the Earth Species Library, please get in touch with [katie@earthspecies.org](mailto:katie@earthspecies.org). 

## Getting Started: 

*   [Introduction to using Collab](https://colab.research.google.com/notebooks/intro.ipynb)
*   [Digital Signal Processing with Python](https://github.com/earthspecies/intro-to-DSP-with-python)

## Resources: 

*   [The “Cocktail Party Problem”: What Is It? How Can It Be Solved? And Why Should Animal Behaviorists Study It?](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2692487/)
*   [Asteroid: The PyTorch-Based Audio Source Separation Toolkit for Researchers](https://arxiv.org/abs/2005.04132)
*   [Wavesplit: End-to-End Speech Separation by Speaker Clustering](https://arxiv.org/abs/2002.08933)
*   [Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separation](https://arxiv.org/abs/2007.13975)
*   [Voice Separation with an Unknown Number of Multiple Speakers](https://arxiv.org/abs/2003.01531)
*   [Separation of Overlapping Sources in Bioacoustic Mixtures](https://asa.scitation.org/doi/10.1121/10.0000932)
*   [Separating Overlapping Bat Calls with a Bi-Directional Long Short-Term Memory Network](https://www.biorxiv.org/content/10.1101/2019.12.15.876656v1)
*   [Music Source Separation in the Waveform Domain](https://arxiv.org/abs/1911.13254)
*   [Deep Audio Prior](https://arxiv.org/abs/1912.10292)
*   [Deep Learning for Monaural Speech Separation](https://paris.cs.illinois.edu/pubs/huang-icassp2014.pdf)
*   [The Separation of Overlapped Dolphin Signature Whistle Based on Blind Source Separation](https://ieeexplore.ieee.org/document/8242534)
*   [A Comparative Study of Blind Source Separation for Bioacoustics Sounds based on FastICA, PCA and NMF](https://www.sciencedirect.com/science/article/pii/S1877050918312468?via%3Dihub)
*   [Investigating Deep Neural Transformations for Spectrogram-Based Musical Source Separation](https://arxiv.org/abs/1912.02591)
*   [A Physiologically Inspired Model for Solving the Cocktail Party Problem](https://link.springer.com/content/pdf/10.1007/s10162-019-00732-4.pdf)
*   [Audio Source Separation with Discriminative Scattering Networks](https://arxiv.org/abs/1412.7022)
*   [Blind Nonnegative Source Separation Using Biological Neural Networks](https://arxiv.org/abs/1706.00382)

# 
**Miscellaneous Key Resources**

*   [End-to-End Overlapped Speech Detection and Speaker Counting with Raw Waveform](https://ieeexplore.ieee.org/document/9003962)
*   [Perceptual and Neural Mechanisms of Auditory Scene Analysis in the European Starling](https://link.springer.com/chapter/10.1007/978-3-319-48690-1_3)
*   [Neuromorphic Model for Sound Source Segregation](https://drum.lib.umd.edu/handle/1903/18155)
*   [Efficient Trainable Front-Ends for Neural Speech Enhancement](https://arxiv.org/abs/2002.09286)
*   [Finding Strength in Weakness: Learning to Separate Sounds with Weak Supervision](https://arxiv.org/abs/1911.02182)
*   [Monaural Source Separation Based on Sequentially Trained LSTMs in Real Room Environments](https://ieeexplore.ieee.org/document/8902640)
*   [The Phasebook: Building Complex Masks via Discrete Representations for Source Separation](https://waseda.pure.elsevier.com/en/publications/the-phasebook-building-complex-masks-via-discrete-representations)
*   [Universal Sound Separation](https://arxiv.org/abs/1905.03330)
*   [Speaker-independent Speech Separation with Deep Attractor Network](https://arxiv.org/abs/1707.03634)
*   [Deep Clustering and Conventional Networks for Music Separation: Stronger Together](https://arxiv.org/abs/1611.06265)
*   [Phase-Sensitive and Recognition-Boosted Speech Separation Using Deep Recurrent Neural Networks](https://ieeexplore.ieee.org/document/7178061)
*   [Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation](https://arxiv.org/abs/1502.04149)
*   [Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation](https://arxiv.org/abs/1809.07454)
*   [Deep Learning Based Phase Reconstruction for Speaker Separation: A Trigonometric Perspective](https://arxiv.org/abs/1811.09010)
*   [Divide and Conquer: A Deep CASA Approach to Talker-independent Monaural Speaker Separation](https://arxiv.org/abs/1904.11148)
*   [Dual-Path RNN: Efficient Long Sequence Modeling for Time-Domain Single-Channel Speech Separation](https://arxiv.org/abs/1910.06379)
*   [A Comprehensive Study of Speech Separation: Spectrogram vs Waveform Separation](https://arxiv.org/abs/1905.07497)
*   [FurcaNeXt: End-to-End Monaural Speech Separation with Dynamic Gated Dilated Temporal Convolutional Networks](https://arxiv.org/abs/1902.04891)
*   [Improving Universal Sound Separation Using Sound Classification](https://arxiv.org/abs/1911.07951)
*   [SpEx: Multi-Scale Time Domain Speaker Extraction Network](https://arxiv.org/abs/2004.08326)
*   [Meta-Learning Extractors for Music Source Separation](https://arxiv.org/abs/2002.07016)
*   [Unsupervised Learning of Semantic Audio Representations](https://arxiv.org/abs/1711.02209)
*   [Sudo rm -rf: Efficient Networks for Universal Audio Source Separation](https://arxiv.org/abs/2007.06833)
*   [Unsupervised Sound Separation Using Mixtures of Mixtures](https://arxiv.org/abs/2006.12701)
*   [Listen to What You Want: Neural Network-based Universal Sound Selector](https://arxiv.org/abs/2006.05712)
*   [Speech Separation Based on Multi-Stage Elaborated Dual-Path Deep BiLSTM with Auxiliary Identity Loss](https://arxiv.org/abs/2008.03149)
*   [Identify Speakers in Cocktail Parties with End-to-End Attention](https://arxiv.org/abs/2005.11408)

# 
**Machine Learning Concepts**

*   Matched Filters
*   Hilbert Huang Transforms
*   Lombard Effect
*   Dip-Listening Hypothesis
*   Noise-Invariant, Rule-Encoding, and Temporal Edge Neurons
*   FastICA (Independent Component Analysis), Point Source Separation (PSS), Non-Negative Matrix Factorization (NMF)
*   Cortical Representation of Speech, Auditory Object Analysis
*   Deep Scattering Spectrum, Kymatio, Invariant Scattering Convolution Networks
*   Error-Gated Hebbian Rule
*   Probabilistic Latent Component Analysis (PLCA), Robust PCA (RPCA), Low-Rank Modeling
*   Progressive Learning
*   Denoising Autoencoders
*   Temporal Convolutional Networks (TCNs)
*   Perfect Reconstruction Filterbank (PRFB), Gammatone Filterbank
*   Deep Feature Losses, Short-Time Objective Intelligibility (STOI), Perceptual Evaluation of Speech Quality (PESQ)
*   Wiener Filtering
*   Permutation Invariant Training
*   Supervised Independent Vector Analysis
*   Phase Spectra and Group Delay
*   Spectrogram Fusion
*   Self-Organizing Background Subtraction
*   Phase-Aware Signal Processing
*   Deep Clustering, Deep Attractor, and Selective Hearing Networks
*   Multimodal/Crossmodal Fusion
